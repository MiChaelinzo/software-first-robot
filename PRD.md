# Planning Guide - v2.0 Enterprise Edition

> **ðŸš€ MAJOR UPDATE**: This system has been upgraded with 4 enterprise AI systems: ML Prediction Engine, Digital Twin Simulator, Swarm Intelligence, and Energy Optimization. See [AI_SYSTEMS_README.md](./AI_SYSTEMS_README.md) for details.

An autonomous warehouse robot simulation platform that demonstrates intelligent pathfinding, task prioritization, adaptive decision-making, and comprehensive fleet management in a dynamic fulfillment center environment. Now featuring **machine learning predictions, digital twin testing, swarm coordination, energy optimization**, advanced analytics, predictive insights, real-time optimization, and multi-layer heat mapping for unprecedented operational intelligence.

**Experience Qualities**:
1. **Intelligent** - The system feels smart and autonomous with robots making real-time decisions, AI-powered optimizations, and predictive analytics forecasting performance trends
2. **Transparent** - Users clearly see robot decision-making, task flows, system performance metrics, historical activity logs, and multi-dimensional heat maps revealing spatial patterns
3. **Dynamic** - The simulation feels alive with continuous activity, real-time graph updates, responsive behavior, scenario generation, and adaptive learning improvements

**Complexity Level**: Complex Application (advanced functionality, likely with multiple views)
This is a sophisticated robotics simulation requiring real-time pathfinding algorithms, state management for multiple autonomous agents, collision detection, task queue management, performance analytics, AI-driven decision making, predictive modeling, fleet command operations, multi-layer spatial analytics, and comprehensive data export capabilities.

## Essential Features

### Multi-Robot Fleet Management
- **Functionality**: Simulate 10 autonomous warehouse robots operating simultaneously in a shared environment with advanced collision avoidance
- **Purpose**: Demonstrate coordination, collision avoidance, and parallel task execution at scale
- **Trigger**: Robots activate automatically on simulation start
- **Progression**: Robot spawns â†’ Requests task assignment â†’ Calculates optimal path â†’ Executes movement â†’ Updates status â†’ Avoids collisions â†’ Requests next task
- **Success criteria**: 10 robots operate without collisions, complete tasks efficiently, maintain coordination, and demonstrate priority-based yielding

### Advanced Collision Avoidance System
- **Functionality**: Multi-layered collision detection with critical distance monitoring, near-miss tracking, priority-based yielding, and adaptive speed learning based on congestion patterns
- **Purpose**: Demonstrate sophisticated spatial awareness, safe autonomous operation at scale, and intelligent traffic management
- **Trigger**: Continuous monitoring during robot movement with real-time traffic analysis
- **Progression**: Detect proximity â†’ Calculate collision risk â†’ Analyze traffic patterns â†’ Adjust speed adaptively â†’ Determine priority â†’ Log event â†’ Update learning model â†’ Resume optimal operation
- **Success criteria**: Zero collisions, logged avoidance events, smooth traffic flow, priority task completion, and measurable efficiency improvements through learning

### Intelligent Pathfinding with A* Algorithm
- **Functionality**: Real-time path calculation considering obstacles, other robots, and task locations
- **Purpose**: Demonstrate autonomous navigation and adaptive behavior
- **Trigger**: Robot receives new task assignment
- **Progression**: Receives destination â†’ Scans environment state â†’ Calculates optimal path using A* â†’ Executes movement with collision avoidance â†’ Recalculates if blocked
- **Success criteria**: Robots find efficient paths, avoid collisions, and adapt to dynamic obstacles

### Dynamic Task Queue System
- **Functionality**: Priority-based task management with automatic assignment to available robots
- **Purpose**: Show intelligent task allocation and workload balancing
- **Trigger**: User creates tasks or simulation generates them automatically
- **Progression**: Task created â†’ Added to queue with priority â†’ System identifies available robot â†’ Assigns based on proximity and capacity â†’ Robot executes â†’ Task marked complete
- **Success criteria**: Tasks assigned efficiently, queue updates in real-time, robots never idle when tasks available

### Real-Time Performance Analytics
- **Functionality**: Live metrics tracking efficiency, completion rates, robot utilization, congestion patterns, and adaptive learning performance
- **Purpose**: Validate robot performance, demonstrate system optimization, and showcase learning improvements
- **Trigger**: Continuous data collection during simulation
- **Progression**: Event occurs â†’ Data logged â†’ Traffic analyzed â†’ Learning metrics updated â†’ Dashboard updates â†’ Historical trends tracked â†’ Efficiency gains calculated
- **Success criteria**: Accurate metrics display, performance trends visible, insights actionable, learning improvements quantified

### Interactive Warehouse Environment
- **Functionality**: Grid-based warehouse with storage zones, charging stations, and dynamic obstacles
- **Purpose**: Provide realistic environment for robot decision-making
- **Trigger**: User configures environment or uses preset layouts
- **Progression**: User places obstacles/zones â†’ Environment validates layout â†’ Pathfinding updates â†’ Robots adapt navigation
- **Success criteria**: Environment updates affect robot behavior, layout persists, zones function as intended

### Real-Time Efficiency Optimizer
- **Functionality**: AI-powered analysis system that continuously evaluates fleet performance and suggests actionable optimizations
- **Purpose**: Provide intelligent, data-driven recommendations to improve warehouse efficiency in real-time
- **Trigger**: User clicks "Analyze System" button or system auto-analyzes every 5 minutes
- **Progression**: Collects metrics â†’ Analyzes patterns â†’ Identifies bottlenecks â†’ Generates suggestions with confidence scores â†’ User applies optimization â†’ System measures impact
- **Success criteria**: Meaningful suggestions generated, clear impact ratings, one-click application, measurable efficiency improvements after application

### Predictive Analytics Dashboard
- **Functionality**: Machine learning-based prediction system that forecasts task throughput, fleet efficiency, path optimization, and safety scores
- **Purpose**: Provide forward-looking insights into system performance trends and potential issues before they occur
- **Trigger**: Continuous real-time analysis with 3-second refresh intervals
- **Progression**: Analyzes historical data â†’ Calculates trend trajectories â†’ Predicts future performance â†’ Assigns confidence scores â†’ Provides recommendations
- **Success criteria**: Accurate trend predictions, high confidence scores, proactive problem identification, actionable recommendations

### Robot Activity History Tracker
- **Functionality**: Comprehensive event logging system tracking all robot activities, task assignments, collisions, and state changes
- **Purpose**: Enable detailed performance analysis, debugging, and identification of patterns in robot behavior
- **Trigger**: Automatic logging of all significant robot events during simulation
- **Progression**: Event occurs â†’ Details captured with timestamp and position â†’ Added to history log â†’ Organized by robot or event type â†’ Statistics calculated
- **Success criteria**: Complete event history, searchable by robot or event type, statistical summaries, maintains last 100 events for performance

### Fleet Command Center
- **Functionality**: Advanced robot management interface with individual speed control, pause/resume, recall to base, and real-time status monitoring
- **Purpose**: Give operators granular control over individual robots for testing, emergency response, or optimization
- **Trigger**: User accesses Management tab and interacts with robot controls
- **Progression**: User selects robot â†’ Views detailed status â†’ Adjusts speed slider or clicks action button â†’ Robot responds immediately â†’ History logged
- **Success criteria**: Responsive individual controls, real-time status updates, smooth speed adjustments, successful pause/resume/recall operations

### Dynamic Scenario Generator
- **Functionality**: Pre-configured simulation scenarios ranging from standard operations to chaos mode, with adjustable robot counts and task rates
- **Purpose**: Enable rapid testing of different operational conditions and stress-testing of the system
- **Trigger**: User selects scenario from preset list or clicks random scenario generator
- **Progression**: User selects scenario â†’ System validates simulation is stopped â†’ Applies robot count and task rate â†’ Resets metrics and state â†’ User starts simulation
- **Success criteria**: Instant scenario application, clear difficulty ratings, diverse testing conditions, random scenario option for variability

### Advanced Multi-Layer Heat Map
- **Functionality**: Four-layer heat map visualization showing traffic density, speed distribution, collision risk zones, and efficiency patterns
- **Purpose**: Provide deep spatial intelligence about warehouse operations through visual analytics
- **Trigger**: Continuous data collection during simulation, viewable in Analytics tab
- **Progression**: Robots move â†’ Data aggregated by grid cell â†’ Heat intensity calculated â†’ Color-coded visualization rendered â†’ Statistics displayed â†’ Layer-specific insights provided
- **Success criteria**: Clear visual differentiation between layers, accurate data representation, smooth rendering, actionable insights per layer

### Real-Time Voice Command Control
- **Functionality**: Natural language voice recognition system allowing hands-free control of simulation, robots, tasks, and views using spoken commands with text-to-speech feedback responses
- **Purpose**: Demonstrate cutting-edge voice UI integration for industrial robotics applications, enabling operators to control systems while performing other tasks and receive immediate auditory confirmation
- **Trigger**: User activates microphone and speaks natural language commands
- **Progression**: User clicks "Start" â†’ Microphone activates â†’ User speaks command â†’ Speech recognized â†’ Pattern matched â†’ Action executed â†’ System speaks confirmation â†’ Visual feedback displayed â†’ Command logged
- **Success criteria**: High accuracy command recognition, natural language processing, comprehensive command library (30+ commands), real-time audio and visual feedback, adjustable voice settings, visual listening and speaking indicators, command history tracking

### Voice Feedback System (Text-to-Speech)
- **Functionality**: Intelligent text-to-speech engine that provides spoken responses to voice commands and status updates, with customizable voice, speed, pitch, and volume settings
- **Purpose**: Create complete voice interaction experience for hands-free operation and accessibility, providing auditory confirmation of commands and system status
- **Trigger**: Voice command executed, status report requested, or system event occurs
- **Progression**: Command recognized â†’ Action executed â†’ TTS generates speech â†’ Audio plays through speakers â†’ Visual indicator shows speaking state â†’ Queue manages multiple messages
- **Success criteria**: Clear, natural-sounding voice output, instant feedback for commands, configurable voice parameters (rate, pitch, volume, voice selection), support for multiple system voices, queue management for overlapping messages, visual speaking indicator, settings persistence

### Audio Cues for Critical Events
- **Functionality**: Real-time audio feedback system using Web Audio API to generate distinct synthesized sounds for collisions, task events, robot status changes, and system actions
- **Purpose**: Provide immediate auditory feedback for critical events, enhancing situational awareness and enabling eyes-free monitoring of warehouse operations
- **Trigger**: Collision events (critical avoidance, near miss, successful avoidance), task assignment/completion, robot charging, system optimization, simulation state changes
- **Progression**: Event occurs â†’ Audio cue type determined â†’ Web Audio oscillator synthesizes tone sequence â†’ Sound plays at configured volume â†’ User receives instant feedback
- **Success criteria**: Distinct, recognizable sounds for each event type, adjustable volume control, enable/disable toggle, minimal latency (<50ms), no performance impact on simulation, persistent user preferences

### AI-Powered System Intelligence
- **Functionality**: LLM-driven task prioritization, optimization suggestions, and adaptive learning system that adjusts robot speeds based on real-time congestion analysis
- **Purpose**: Demonstrate AI integration in robotics control systems and autonomous optimization capabilities
- **Trigger**: System requests optimization, user asks for insights, or congestion patterns trigger adaptive adjustments
- **Progression**: System collects current state â†’ Analyzes traffic patterns â†’ Generates prompt â†’ LLM analyzes â†’ Returns recommendations â†’ System applies adaptive speed adjustments or presents to user â†’ Measures efficiency gains
- **Success criteria**: Meaningful insights generated, recommendations improve efficiency, AI responds contextually, adaptive learning reduces congestion and increases throughput

### Adaptive Congestion Learning System
- **Functionality**: Real-time traffic pattern analysis with zone-based congestion tracking, historical data learning, and dynamic speed adjustments to optimize throughput
- **Purpose**: Demonstrate machine learning principles in robotics, reduce congestion, prevent collisions, and continuously improve system efficiency
- **Trigger**: Continuous analysis during simulation with speed adjustments every update cycle
- **Progression**: Analyze robot positions â†’ Calculate zone congestion â†’ Review historical patterns â†’ Predict optimal speeds â†’ Apply adaptive adjustments â†’ Record results â†’ Update learning model â†’ Calculate efficiency gains
- **Success criteria**: Measurable reduction in congestion over time, improved robot throughput, fewer collision events, positive efficiency gain percentage, smooth traffic flow in high-density zones

### Heat Trail Visualization System
- **Functionality**: Real-time visualization of historical robot paths with speed-based color coding and decay effects, plus traffic heat mapping showing high-frequency zones
- **Purpose**: Provide visual insights into robot movement patterns, speed distribution, traffic hotspots, and system efficiency over time
- **Trigger**: Continuous recording during robot movement with automatic decay and cleanup
- **Progression**: Robot moves â†’ Position recorded with speed and timestamp â†’ Trail point added to history â†’ Heat map cell updated â†’ Decay applied over time â†’ Visual overlay rendered with speed colors â†’ Statistics calculated
- **Success criteria**: Smooth trail rendering with accurate speed colors, heat map shows traffic patterns clearly, trails fade naturally over time, performance remains optimal with multiple trails active

### 3D Warehouse Visualization
- **Functionality**: Immersive Three.js-powered 3D perspective view of the warehouse environment with real-time robot animation, path visualization, and dynamic lighting
- **Purpose**: Provide a compelling, realistic view of warehouse operations that showcases spatial awareness, depth perception, and professional presentation quality
- **Trigger**: User switches to 3D View tab
- **Progression**: Scene initializes â†’ Camera orbits warehouse â†’ Robots animate in 3D space â†’ Paths render as glowing trails â†’ Tasks float and rotate â†’ Lighting responds to robot movement â†’ Camera follows action
- **Success criteria**: Smooth 60fps rendering, robots move fluidly in 3D space, paths are clearly visible, warehouse elements have realistic depth and shadows, camera provides cinematic perspective

## Edge Case Handling
- **Robot Collision**: Robots detect proximity and pause/reroute to avoid collisions; congestion system learns from near-misses and adjusts speeds in high-traffic zones
- **Unreachable Destination**: Task reassigned or marked as blocked if path cannot be found after multiple attempts
- **Task Queue Empty**: Robots enter idle mode and return to charging stations
- **Simultaneous Task Assignment**: Locking mechanism ensures tasks assigned to only one robot
- **Environment Changes**: Robots recalculate paths mid-route if obstacles appear
- **Performance Degradation**: System alerts user if robot efficiency drops below threshold
- **High Congestion**: Adaptive learning system reduces speeds in congested zones and learns optimal traffic patterns over time; audio cues alert operators to critical situations
- **Critical Priority Tasks**: System maintains higher speeds for critical tasks even in congested areas; distinct audio cues indicate priority task events
- **Learning Rate Adjustment**: System dynamically adjusts learning rate based on success metrics and collision avoidance performance
- **Trail Memory Overflow**: Heat trail system automatically cleans up old trail points and heat map cells to maintain performance
- **Multiple Active Trails**: System efficiently handles 10+ simultaneous robot trails with smooth rendering and minimal performance impact
- **Heat Map Saturation**: Heat map normalizes intensity values to prevent oversaturation in heavily-trafficked zones
- **3D Rendering Performance**: WebGL renderer automatically adjusts quality based on device capability; fallback to 2D view if Three.js fails to initialize
- **3D Camera Reset**: User can manually reset camera position if auto-orbit becomes disorienting
- **Multiple Simultaneous Views**: System optimizes rendering when both 2D and 3D views exist but only renders active tab
- **Audio Context Limitations**: System gracefully handles browsers that don't support Web Audio API with disabled audio controls and informative messaging
- **Overlapping Audio Cues**: Multiple simultaneous events trigger sequential audio cues to prevent audio clipping or confusion
- **Audio Volume Management**: Independent volume controls for voice feedback (TTS) and audio cues allow user preference customization

## Design Direction
The design should evoke a sense of advanced technology and precision engineering - like stepping into a mission control center for an automated warehouse. It should feel professional, data-rich, and futuristic while maintaining clarity and usability. The interface should communicate intelligent automation, real-time monitoring, and cutting-edge robotics technology.

## Color Selection
A high-tech, cyberpunk-inspired palette with electric accents on dark surfaces, evoking advanced robotics and AI systems.

- **Primary Color**: oklch(0.55 0.25 265) - Deep electric blue communicating intelligence, technology, and precision
- **Secondary Colors**: oklch(0.25 0.02 265) for dark surfaces creating depth and focus, oklch(0.35 0.05 265) for elevated panels suggesting layered interfaces
- **Accent Color**: oklch(0.75 0.20 145) - Bright cyan for robot paths, active states, and CTAs drawing attention to key interactions
- **Foreground/Background Pairings**: 
  - Primary (Electric Blue oklch(0.55 0.25 265)): White text (oklch(0.98 0 0)) - Ratio 5.2:1 âœ“
  - Accent (Cyan oklch(0.75 0.20 145)): Dark text (oklch(0.20 0.02 265)) - Ratio 8.1:1 âœ“
  - Background (Deep Navy oklch(0.25 0.02 265)): Light text (oklch(0.90 0.01 265)) - Ratio 10.5:1 âœ“
  - Secondary (Medium Blue oklch(0.35 0.05 265)): Light text (oklch(0.95 0.01 265)) - Ratio 8.8:1 âœ“

## Font Selection
Typography should communicate precision, technology, and modern engineering through geometric, technical typefaces.

- **Typographic Hierarchy**:
  - H1 (Main Title): Space Grotesk Bold / 32px / tight tracking (-0.02em) - Commands attention with technical authority
  - H2 (Section Headers): Space Grotesk SemiBold / 20px / normal tracking - Clear section delineation
  - H3 (Panel Labels): Space Grotesk Medium / 16px / slight tracking (0.01em) - Precise labeling
  - Body (Metrics/Data): JetBrains Mono Regular / 14px / normal tracking - Technical data with monospace precision
  - Small (Status Text): Space Grotesk Regular / 12px / wide tracking (0.02em) - Subtle supporting information
  - Numbers (Performance Data): JetBrains Mono Medium / varies / tabular-nums - Aligned numerical displays

## Animations
Animations should emphasize the mechanical precision and fluid intelligence of autonomous systems, with smooth pathfinding visualization and subtle UI feedback that feels responsive but never distracting.

- Robot movement: Smooth easing with slight deceleration at waypoints (cubic-bezier(0.4, 0, 0.2, 1))
- Path visualization: Animated stroke dashoffset creating "drawing" effect at 300ms
- Task assignment: Pulse animation on robot selection (200ms) followed by path trace
- Metrics updates: Number counter animations with 400ms duration for satisfaction
- Panel transitions: Slide and fade (250ms) with slight blur for depth
- Robot status changes: Color transition over 300ms with subtle scale pulse (1.05x for 150ms)
- Collision warnings: Urgent pulse at 500ms intervals with red accent
- Success celebrations: Gentle confetti burst and green glow (600ms total)
- Heat trail rendering: Smooth fade-in over 200ms with pathLength animation for line segments
- Trail decay: Gradual opacity reduction over 5 seconds creating natural fade-out effect
- Heat map cells: Emerge with 500ms fade-in and scale animation, blend mode creates layered depth
- Speed color transitions: Instant color changes based on robot speed for immediate visual feedback
- 3D robot movement: Smooth interpolated position updates with gentle floating animation (0.05 units at 5ms intervals)
- 3D camera orbit: Slow rotation around warehouse center at 0.001 radians per frame when simulation running
- 3D robot rotation: Continuous spin on moving robots at 0.05 radians per frame for dynamic feel
- 3D task indicators: Hover animation with 0.1 unit vertical oscillation at 3ms intervals
- 3D lighting: Point lights pulse with robot status changes, emissive intensity varies 0.2-0.5
- 3D path lines: Fade in/out over 300ms when paths change, glowing effect matches robot color
- Voice indicator: Pulsing microphone icon with scale animation (1-1.2x over 1.5s), listening bars animate with staggered delays
- Voice command feedback: Toast notifications slide in from right with 200ms duration, accent color for command confirmations
- Transcript display: Fade in from top with -10px y offset over 200ms, interim text shown in italic with reduced opacity
- Voice speaking indicator: Transform microphone to speaker icon with 200ms transition, primary color scheme when speaking vs accent when listening
- TTS settings sliders: Smooth value changes with 150ms transition, real-time preview updates, disabled state with 50% opacity
- Voice test button: Pulse animation on click, disabled state during speech playback
- Audio cue playback: Instant oscillator synthesis with <50ms latency, smooth exponential fade-out for natural sound decay
- Audio settings panel: Toggle transitions over 200ms, volume slider updates in real-time with 150ms smoothing
- Event-triggered sounds: Immediate playback synchronized with visual events, no perceptible delay between action and audio feedback
- Sound wave animations: Visual feedback indicators pulse in sync with audio playback for enhanced user awareness

## Component Selection
- **Components**: 
  - Card for robot status panels and metrics dashboards with glassmorphism effect
  - Badge for robot states (idle/moving/charging) and task priorities
  - Button for simulation controls with primary/secondary variants
  - Tabs for switching between 2D simulation view, 3D immersive view, analytics, management, and voice control
  - Dialog for task creation and environment configuration
  - Slider for simulation speed control
  - Progress for robot battery levels and task completion
  - Table for task queue display with sortable columns
  - Tooltip for detailed robot information on hover
  - Alert for system warnings and optimization suggestions
  - Switch for 3D view controls (paths, grid, lighting)
  - ScrollArea for voice command lists and recent command history
  - Select for voice selection dropdown
  - Slider for TTS rate, pitch, and volume controls
  - Switch for enabling/disabling voice feedback
  - Card for audio settings panel with glassmorphism
  - Switch for enabling/disabling audio cues
  - Slider for audio cue volume control
  - Badge for audio support status indicators

- **Customizations**: 
  - Custom robot visualizations using SVG with directional indicators
  - Custom grid-based warehouse environment with canvas rendering
  - Custom path visualization with animated bezier curves
  - Custom performance charts using recharts with streaming data
  - Glassmorphic panels with backdrop-filter blur and subtle borders
  - Three.js 3D scene with custom robot models, warehouse geometry, and dynamic lighting
  - WebGL-powered real-time rendering with shadows, fog, and post-processing effects
  - Custom voice indicator with animated microphone and sound wave bars
  - Real-time transcript display with interim results shown in muted style
  - Custom voice feedback settings panel with adjustable TTS parameters
  - Dual-mode voice indicator (listening/speaking) with icon morphing animation
  - Custom audio settings panel with Web Audio API integration
  - Real-time audio cue synthesis using oscillators and gain nodes
  - Visual event type indicators color-coded for each audio cue category

- **States**: 
  - Buttons: Default (subtle glow), hover (brighter glow + lift), active (pressed inset), disabled (50% opacity)
  - Robot cards: Idle (muted), active (accent border + shadow), selected (bright accent glow), error (red pulse)
  - Task rows: Pending (normal), assigned (blue tint), in-progress (animated border), complete (green with fade-out)
  - Grid cells: Empty (subtle grid), obstacle (solid dark), storage (blue tint), charging (yellow glow), occupied (robot color)

- **Icon Selection**: 
  - Robot/AndroidLogo for fleet icons
  - Lightning for charging stations
  - Package for storage zones and tasks
  - ArrowsClockwise for pathfinding recalculation
  - Play/Pause/Stop for simulation controls
  - SpeedometerHigh for performance metrics
  - Warning for collision alerts
  - CheckCircle for completed tasks
  - Brain for AI suggestions
  - Path for heat trail visualization toggle
  - Fire for heat map overlay toggle
  - Gauge for speed indicators
  - MapPin for trail point markers
  - Cube for 3D view mode
  - GridFour for 3D grid toggle
  - Microphone for voice listening state
  - MicrophoneSlash for inactive voice state
  - SpeakerHigh for TTS speaking state and voice feedback settings
  - SpeakerSlash for disabled voice feedback
  - SpeakerHigh for audio cues enabled state
  - SpeakerSlash for audio cues disabled state
  - WaveformCircle for audio cue visualization (if needed)

- **Spacing**: 
  - Panel padding: p-6 for main containers, p-4 for nested cards
  - Grid gaps: gap-4 for dashboard layout, gap-2 for compact metric displays
  - Element margins: mb-6 between major sections, mb-3 between related groups
  - Icon spacing: gap-2 between icon and label in buttons/badges
  - Warehouse grid: Base cell size 40px with 1px gaps

- **Mobile**: 
  - Stack simulation view above analytics dashboard
  - Collapse robot detail panels into accordions
  - Reduce warehouse grid cell size to 24px for better fit
  - Convert metric cards to horizontal scrollable carousel
  - Move simulation controls to fixed bottom bar
  - Single column layout for all sections
  - Hamburger menu for secondary navigation
  - Touch-friendly 48px minimum touch targets
  - 3D view defaults to disabled on mobile for performance, with opt-in toggle
  - Reduced polygon count and simpler materials in mobile 3D view
  - Tab bar becomes horizontally scrollable on narrow screens
